import datetime
import json
from typing import Any, TextIO, cast

import click
from aws_lambda_typing.context import Context
from aws_lambda_typing.events.event_bridge import EventBridgeEvent
from aws_lambda_typing.events.sqs import SQSEvent, SQSMessage

from hyperion.config import queue_config
from hyperion.dateutils import utcnow
from hyperion.infrastructure.message_queue import SourceBackfillMessage, create_backfill_event
from hyperion.log import get_logger
from hyperion.sources.base import Source, SourceEventType, SourceParamsType
from hyperion.typeutils import is_typed_dict_instance

logger = get_logger("hyperion-source-runner")


def _assert_source_event_type(obj: Any) -> SourceEventType | None:
    if obj is None:
        return None
    if not isinstance(obj, dict):
        raise TypeError(f"Invalid source event type, expected 'dict', got {type(obj)!r}.")
    if is_typed_dict_instance(obj, EventBridgeEvent):
        return cast(EventBridgeEvent, obj)
    if "Records" in obj:
        if not obj["Records"]:
            return cast(SQSEvent, obj)
        if isinstance(obj["Records"][0], dict) and is_typed_dict_instance(obj["Records"][0], SQSMessage):
            return cast(SQSEvent, obj)
    raise TypeError("Invalid source event type, expected SQSEvent or EventBridgeEvent.")


def _context_from_obj(obj: Any) -> Context | None:
    if obj is None:
        return None
    if not isinstance(obj, dict):
        raise TypeError(f"Invalid source context type, expected 'dict', got {type(obj)!r}.")
    context = Context()
    for key, value in obj.items():
        if key in vars(context):
            setattr(context, key, value)
    return context


def _enforce_file_queue(queue_path: str, *, path_overwrite: bool) -> None:
    if queue_config.url is not None:
        logger.warning(
            "Direct (aka Argo Workflows) run mode requires FileQueue, "
            "but SQS queue was configured. Configuration will be discarded. "
            "If this is breaking your use-case, please open an issue.",
            url="https://github.com/tomasvotava/hyperion/issues/new",
        )
    queue_config.url = None
    queue_config.path = queue_path
    queue_config.path_overwrite = path_overwrite


def _resolve_file_or_str_option(
    str_option: str | None, file_option: TextIO | None, name: str
) -> SourceParamsType | None:
    if str_option is not None and file_option is not None:
        raise ValueError(f"Only one of --{name} or --{name}-from may be specified, not both.")
    loaded: Any = None
    if str_option is not None:
        loaded = json.loads(str_option)
    elif file_option is not None:
        loaded = json.load(file_option)
    if not isinstance(loaded, list | dict) and loaded is not None:
        raise ValueError("Invalid parameters provided, not a valid json object nor array.")
    return loaded


def _create_argo_run_cli_command(group: click.Group, source_cls: type[Source]) -> click.Command:
    @group.command(
        "run",
        short_help="Run the source locally (aka 'Argo Workflow' mode).",
        help="Run the source locally. Uses FileQueue to dump all of the messages into a JSON file. "
        "This file can be used to further process the assets generated by the source.",
    )
    @click.option("--start-date", type=click.DateTime(), default=None, help="Optional start date to pass to the source")
    @click.option("--end-date", type=click.DateTime(), default=None, help="Optional end date to pass to the source.")
    @click.option("--params", type=click.STRING, default=None, help="JSON params passed to the source.")
    @click.option(
        "--params-from",
        type=click.File("r"),
        default=None,
        help="Path to a file (or - for STDIN) containing JSON params for the source.",
    )
    @click.option(
        "--queue-file",
        type=click.Path(file_okay=True, dir_okay=False, writable=True, resolve_path=True),
        default=None,
        help="This option allows you to override HYPERION_QUEUE_PATH env variable.",
    )
    @click.option(
        "--queue-overwrite",
        type=click.BOOL,
        default=False,
        is_flag=True,
        help="This option allows you to override HYPERION_QUEUE_PATH_OVERWRITE env variable.",
    )
    def argo_run(
        start_date: datetime.datetime | None = None,
        end_date: datetime.datetime | None = None,
        params: str | None = None,
        params_from: TextIO | None = None,
        queue_file: str | None = None,
        queue_overwrite: bool = False,
        source_cls: type[Source] = source_cls,
    ) -> None:
        source_params = _resolve_file_or_str_option(params, params_from, "params")

        if queue_file:
            _enforce_file_queue(queue_file, path_overwrite=queue_overwrite)

        source_cls.handle_argo_workflow_run(start_date=start_date, end_date=end_date, params=source_params)

    return argo_run


def _create_lambda_run_cli_command(group: click.Group, source_cls: type[Source]) -> click.Command:
    @group.command(
        "lambda",
        short_help="Run the source imitating an AWS Lambda event.",
        help="Run the source optionally imitating an AWS Lambda event. "
        "This can be used to test your source's lambda-readiness locally.",
    )
    @click.option(
        "--event",
        type=click.STRING,
        default=None,
        help="Optional JSON-serialized lambda event (e.g. SQSEvent or EventBridgeEvent) for the source.",
    )
    @click.option("--event-from", type=click.File("r"), default=None, help="Path to JSON-serialized lambda event.")
    @click.option("--context", type=click.STRING, default=None, help="JSON-serialized context for the source.")
    @click.option(
        "--context-from", type=click.File("r"), default=None, help="Path to JSON_serialized context for the source."
    )
    @click.option("--params", type=click.STRING, default=None, help="JSON params passed to the source.")
    @click.option(
        "--params-from",
        type=click.File("r"),
        default=None,
        help="Path to a file (or - for STDIN) containing JSON params for the source.",
    )
    def lambda_run(
        event: str | None = None,
        event_from: TextIO | None = None,
        context: str | None = None,
        context_from: TextIO | None = None,
        params: str | None = None,
        params_from: TextIO | None = None,
    ) -> None:
        source_params = _resolve_file_or_str_option(params, params_from, "params")
        source_event = _resolve_file_or_str_option(event, event_from, "event")
        source_context = _resolve_file_or_str_option(context, context_from, "context")
        source_cls.handle_aws_lambda_event(
            _assert_source_event_type(source_event), _context_from_obj(source_context), params=source_params
        )

    return lambda_run


def _create_lambda_backfill_cli_command(group: click.Group, source_cls: type[Source]) -> click.Command:
    @group.command(
        "backfill",
        short_help="Run the source by generating a BackfillSourceEvent.",
        help="Run the source by generating a BackfillSourceEvent. "
        "This will allow you to run the source in AWS Lambda mode, but makes it easier to provide start and end dates.",
    )
    @click.option("--start-date", type=click.DateTime(), required=True, help="Backfill start date")
    @click.option("--end-date", type=click.DateTime(), default=None, help="Backfill end date (defaults to now)")
    @click.option("--params", type=click.STRING, default=None, help="JSON params passed to the source.")
    @click.option(
        "--params-from",
        type=click.File("r"),
        default=None,
        help="Path to a file (or - for STDIN) containing JSON params for the source.",
    )
    @click.option(
        "--notify/--no-notify",
        type=click.BOOL,
        is_flag=True,
        default=False,
        help="Whether the source should notify about each asset generated during the run. "
        "Sometimes (e.g. when running long backfills) it may be beneficial to skip notification so that "
        "queue consumers don't get too many starts. Defaults to --no-notify.",
    )
    def backfill(
        start_date: datetime.datetime,
        end_date: datetime.datetime | None = None,
        params: str | None = None,
        params_from: TextIO | None = None,
        notify: bool = False,
    ) -> None:
        end_date = end_date or utcnow()
        source_params = _resolve_file_or_str_option(params, params_from, "params")
        message = SourceBackfillMessage(
            source=source_cls.source, start_date=start_date, end_date=end_date, notify=notify
        )
        event = create_backfill_event(message, message_id="cli-backfill")
        source_cls.handle_aws_lambda_event(event=event, params=source_params)

    return backfill


class SourceRunner:
    def __init__(self, *sources: type[Source]) -> None:
        self.sources = {source.source: source for source in sources}

    def cli(self) -> None:
        @click.group()
        def cli() -> None:
            pass

        for name, source_cls in self.sources.items():
            logger.debug("Registering CLI handlers for source.", source=name, source_cls=source_cls)
            group = click.Group(name=name)

            _create_argo_run_cli_command(group, source_cls)
            _create_lambda_run_cli_command(group, source_cls)
            _create_lambda_backfill_cli_command(group, source_cls)
            cli.add_command(group)
        cli()
